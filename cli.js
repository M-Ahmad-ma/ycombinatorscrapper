const YCombinatorScraper = require('./src/scraper');
const PuppeteerScraper = require('./src/puppeteerScraper');
const PDFGenerator = require('./src/pdfGenerator');
const fs = require('fs');

async function main() {
  const args = process.argv.slice(2);
  
  if (args.length === 0 || args[0] === '--help' || args[0] === '-h') {
    console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          Y Combinator Scraper - Help                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  Usage: node cli.js <command> [format] [options]            â•‘
â•‘                                                              â•‘
â•‘  COMMANDS:                                                    â•‘
â•‘    batch <batch>         Scrape a specific YC batch         â•‘
â•‘    search <query>        Search companies by keyword         â•‘
â•‘    company <name>        Get detailed info on a company      â•‘
â•‘    all                   Scrape all companies                 â•‘
â•‘                                                              â•‘
â•‘  FORMATS: pdf (default), json, csv                           â•‘
â•‘                                                              â•‘
â•‘  OPTIONS:                                                      â•‘
â•‘    --output=<name>        Output filename                     â•‘
â•‘    --limit=<n>            Number of companies to get         â•‘
â•‘    --pages=<n>            Pages from Algolia (default: 1)    â•‘
â•‘    --detail                Get full details (Puppeteer)       â•‘
â•‘    --batch=<name>         Filter by batch                    â•‘
â•‘    --industry=<name>      Filter by industry                  â•‘
â•‘                                                              â•‘
â•‘  EXAMPLES:                                                    â•‘
â•‘    # Batch scraping with limited detailed results             â•‘
â•‘    node cli.js batch W26 pdf --limit=30 --detail             â•‘
â•‘    node cli.js batch W24 json --limit=50 --output=w24-detailedâ•‘
â•‘                                                              â•‘
â•‘    # Search with details                                      â•‘
â•‘    node cli.js search AI json --limit=20 --detail             â•‘
â•‘                                                              â•‘
â•‘    # Single company full details                              â•‘
â•‘    node cli.js company Stripe pdf --detail                     â•‘
â•‘                                                              â•‘
â•‘    # Multiple pages                                           â•‘
â•‘    node cli.js batch W26 pdf --pages=3 --limit=100           â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);
    return;
  }

  const command = args[0].toLowerCase();
  
  let format = 'pdf';
  let filename = 'startups';
  let filters = {};
  let pagesToScrape = 1;
  let detailLimit = 0;
  let getDetails = false;

  for (let i = 1; i < args.length; i++) {
    const arg = args[i];
    
    if (arg === 'pdf' || arg === 'json' || arg === 'csv') {
      format = arg.toLowerCase();
    } else if (arg.startsWith('--output=')) {
      filename = arg.split('=')[1];
    } else if (arg.startsWith('--limit=')) {
      detailLimit = parseInt(arg.split('=')[1]) || 0;
    } else if (arg.startsWith('--pages=')) {
      pagesToScrape = parseInt(arg.split('=')[1]) || 1;
    } else if (arg.startsWith('--batch=')) {
      filters.batch = arg.split('=')[1];
    } else if (arg.startsWith('--industry=')) {
      filters.industry = arg.split('=')[1];
    } else if (arg.startsWith('--query=')) {
      filters.query = arg.split('=')[1];
    } else if (arg === '--detail') {
      getDetails = true;
    } else if (!arg.startsWith('--') && command === 'batch') {
      filters.batch = arg;
    } else if (!arg.startsWith('--') && command === 'search') {
      filters.query = arg;
    } else if (!arg.startsWith('--') && command === 'company') {
      filters.query = arg;
    }
  }

  const scraper = new YCombinatorScraper({ outputDir: './output' });
  const puppeteerScraper = new PuppeteerScraper();
  const pdfGenerator = new PDFGenerator('./output');

  console.log('\nğŸš€ Y Combinator Scraper\n');

  try {
    let defaultFilename = 'startups';
    let algoliaCompanies = [];
    
    switch (command) {
      case 'batch':
        console.log(`ğŸ“¦ Fetching batch: ${filters.batch || args[1]}`);
        if (!filters.batch) filters.batch = args[1];
        algoliaCompanies = await scraper.scrapeBatchWithPages(filters.batch, pagesToScrape);
        defaultFilename = (filters.batch || 'batch').toLowerCase();
        break;

      case 'search':
        console.log(`ğŸ” Searching: ${filters.query || args[1]}`);
        if (!filters.query) filters.query = args[1];
        algoliaCompanies = await scraper.search(filters.query);
        defaultFilename = (filters.query || 'search').toLowerCase().replace(/\s+/g, '-');
        break;

      case 'company':
        console.log(`ğŸ¢ Getting company: ${args[1]}`);
        const companyData = await scraper.search(args[1]);
        if (companyData.length > 0) {
          algoliaCompanies = [companyData[0]];
        }
        defaultFilename = (args[1] || 'company').toLowerCase().replace(/\s+/g, '-');
        break;

      case 'url':
        console.log(`ğŸŒ Scraping from Algolia...`);
        algoliaCompanies = await scraper.scrapeWithFilters({});
        defaultFilename = 'url-scrape';
        break;

      case 'all':
        console.log(`ğŸ“š Fetching all companies (${pagesToScrape} pages)...`);
        algoliaCompanies = await scraper.scrapeAllPages(pagesToScrape);
        defaultFilename = 'all-companies';
        break;

      default:
        console.log(`Unknown command: ${command}`);
        console.log('Use --help for usage information');
        return;
    }

    if (filename === 'startups') {
      filename = defaultFilename;
    }

    console.log(`\nâœ… Found ${algoliaCompanies.length} companies from Algolia\n`);

    if (algoliaCompanies.length === 0) {
      console.log('No companies found.');
      return;
    }

    // Show summary
    console.log('First 5 companies:');
    algoliaCompanies.slice(0, 5).forEach((c, i) => {
      console.log(`  ${i + 1}. ${c.name} (${c.batch}) - ${c.industry}`);
    });

    let companies = algoliaCompanies;

    // Get detailed info for limited companies
    if (getDetails && detailLimit > 0) {
      console.log(`\nğŸ” Getting FULL details for ${detailLimit} companies using Puppeteer...`);
      companies = await puppeteerScraper.scrapeMultipleCompanies(algoliaCompanies, {
        limit: detailLimit,
        concurrent: 3,
        delay: 1500
      });
      
      console.log(`\nâœ… Got detailed info for ${companies.filter(c => c.details).length} companies`);
    } else if (getDetails && command === 'company') {
      console.log(`\nğŸ” Getting FULL details using Puppeteer...`);
      const details = await puppeteerScraper.scrapeCompanyFullDetails(algoliaCompanies[0]?.slug);
      if (details) {
        algoliaCompanies[0].details = details;
        companies = algoliaCompanies;
      }
    }

    console.log(`\nğŸ’¾ Saving ${companies.length} companies as ${format.toUpperCase()}...`);

    switch (format) {
      case 'pdf':
        const pdfPath = await pdfGenerator.generatePDF(companies, `${filename}.pdf`);
        console.log(`ğŸ“„ PDF saved: ${pdfPath}`);
        break;
        
      case 'json':
        const jsonPath = `./output/${filename}.json`;
        fs.writeFileSync(jsonPath, JSON.stringify(companies, null, 2));
        console.log(`ğŸ“‹ JSON saved: ${jsonPath}`);
        break;
        
      case 'csv':
        const headers = ['name', 'description', 'batch', 'industry', 'founders', 'website', 'launchDate'];
        const csvContent = [
          headers.join(','),
          ...companies.map(row => headers.map(h => {
            let val = '';
            if (h === 'founders') {
              val = Array.isArray(row.details?.founders) 
                ? row.details.founders.map(f => f.name).join('; ')
                : (row[h] || '');
            } else {
              val = row[h] || '';
            }
            return `"${val.replace(/"/g, '""')}"`;
          }).join(','))
        ].join('\n');
        const csvPath = `./output/${filename}.csv`;
        fs.writeFileSync(csvPath, csvContent);
        console.log(`ğŸ“Š CSV saved: ${csvPath}`);
        break;
    }

    // Always save detailed JSON when --detail is used
    if (getDetails || detailLimit > 0) {
      const detailedCompanies = companies.filter(c => c.details);
      if (detailedCompanies.length > 0) {
        const detailPath = `./output/${filename}-detailed.json`;
        fs.writeFileSync(detailPath, JSON.stringify(detailedCompanies, null, 2));
        console.log(`ğŸ” Detailed info saved: ${detailPath}`);
      }
    }

  } catch (error) {
    console.error('âŒ Error:', error.message);
    console.error(error.stack);
  }

  console.log('\nâœ¨ Done!\n');
}

main().catch(console.error);
